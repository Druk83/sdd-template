# Испытание системы — шаблон ПМИ (универсальная инструкция)

Назначение:
- по документации проекта в `docs/` подготовить **готовый документ ПМИ** (Программа и методика испытаний);
- документ должен быть самодостаточным: цели, условия/стенд, программа испытаний (реестр), методики, порядок проведения, артефакты и критерии завершения.

## Выход (что агент обязан создать)
- **Файл:** `docs/requirements/тестирование/испытание системы.md`
- **Содержание файла:** готовый документ **«Программа и методика испытаний <PROJECT_NAME>»** по структуре ниже.

Правила:
- Источники — **только документы из `docs/`** (наименование документа + конкретные пункты/разделы).
- Не вводить новые сущности/реестры/ключи, которых нет в проекте.
- Связь “программа → методики” делать через **ID проверки внутри ПМИ** (например `T-001`), независимые от оглавления.

---

## Обязательная структура (жёстко — агент обязан следовать)
Агент при генерации файла `docs/requirements/тестирование/испытание системы.md` обязан **строго** сформировать следующие разделы и подпункты в указанном формате (без произвольных замен названий разделов):

1) **1. Титульная часть**
   - `Наименование: <PROJECT_NAME>` (строго);
   - `Вид испытаний:` если есть в `docs/`, иначе `Не задано в docs`;
   - `Версия/Дата` — указывать значение и источник (файл и раздел).

2) **2. Общие положения**
   - `Назначение`; `Объект испытаний` (in scope / out of scope — перечислять пункты с явными ссылками на `docs/<path>#<heading>`).
   - `Основания`: явный список документов из `docs/` (файл + пункт).

3) **3. Приёмочные критерии**
   - Каждое требование оформлять как строку: `ID требования | Текст требования | Значение/порог | Источник (docs/<file>#<section>)`.
   - Любой порог (p95, availability, RTO и т.п.) должен быть в явном формате (например `p95 <= 200 ms`).

4) **4. Условия проведения**
   - `Стенд`: таблица компонентов (имя сервиса | роль | хост/порт если задано в docs | источник).
   - `ПО и конфигурации`: перечисление версий из `docs/` или `Не задано`.

5) **5. Подготовка к испытаниям** — чёткие entry-conditions (каждое условие с источником).

6) **6. Реестр проверок (обязательно)** — таблица с колонками строго в порядке:
   `ID проверки | Наименование | Источник (docs/<file>#<section>) | Проверяемый параметр | Вид испытаний | Условия/стенд | Артефакты | Критерий pass/fail`.
   - `ID проверки` — формат `T-001`, `T-002` … (порядок генерации — последовательный); агент обязан сгенерировать уникальные ID.
   - В колонке `Источник` обязательно указывать файл и точный раздел/параграф (например `docs/requirements/требования/…#1.4.3.1`).
   - `Критерий pass/fail` — однозначный: либо `pass` при выполнении условия, либо `fail`, с указанием измеряемого значения если применимо.

7) **7. Методики (по ID проверки)** — для каждой строки реестра должна быть секция `T-XXX — <наименование>` с полями: `Цель`, `Основание (ссылка)`, `Средства` (или `Не задано в docs`), `Шаги` (нумерованный список), `Ожидаемый результат` (phrase `pass/fail`), `Артефакты`, `Оценка соответствия`.

8) **8. Порядок проведения** — последовательность этапов (см. пример) и правило перехода: переход разрешён **только** после фиксированного протокола предыдущего этапа.

9) **9. Протоколирование и отчётность** — таблицы/форматы протоколов должны быть описаны; для каждой проверки — поля: `ID проверки`, `Результат`, `Измерения`, `Замечания`, `Ссылки на артефакты`.

10) **10. Критерии завершения / 11. Работы после завершения** — явные exit-условия и список работ post-mortem.

---

## Форматы и машинопроверяемые артефакты (обязательно)
Агент обязан сгенерировать и вернуть вместе с `docs/requirements/тестирование/испытание системы.md` **машинно-парсимый реестр** в `docs/requirements/тестирование/реестр_проверок.yaml` или `json` с массивом объектов вида:

{
  "id": "T-001",
  "title": "<название>",
  "source": "docs/...#...",
  "parameter": "p95 <= 200 ms",
  "type": "load|functional|security|stability|backup",
  "stand": "<описание стенда или ссылка>",
  "artifacts": ["k6-report.json", "dump.sql", "screenshot.png"],
  "pass_criteria": "pass if p95 <= 200 ms",
  "owner": "<team/person>"
}

Это позволит автоматическим проверкам валидировать соответствие ПМИ структуре.

---

## Жёсткие правила поведения агента
- **Не придумывать** значения: если какое-то поле не задано в `docs/`, записать `Не задано в docs (проверено: [<list of checked docs>])` и создать задачу `.tasks/<id>` с описанием недостающего факта.
- Все ссылки на требования/стенд/версии должны ссылаться на фактические файлы в `docs/` с указанным разделом/параграфом.
- Агент **обязуется** формировать `реестр_проверок.{json,yaml}` и не считать markdown единственным источником машинной правды.

---

## Definition of Done (обновлено)
Файл `docs/requirements/тестирование/испытание системы.md` считается готовым только если выполнены дополнительные машинные проверки:
- присутствуют все разделы 1–11 в требуемом формате;
- файл `docs/requirements/тестирование/реестр_проверок.{json,yaml}` присутствует и проходит валидацию схемы (есть id, source, pass_criteria);
- для каждой строки реестра есть соответствующая методика в разделе 7;
- если встречены незаданные факты — для каждого создана задача `.tasks/<id>`.

**Примечание:** эти требования — минимальные. Дополнительные детали (конкретные шаги методик) агент должен брать из `docs/` или запрашивать дополнения через задачи.


---

## Требования к оформлению ПМИ
- Деловой связный текст + таблицы.
- Каждая проверка в программе испытаний обязана иметь:
  - источник в `docs/` (документ + пункт/раздел),
  - критерий pass/fail,
  - артефакты (что сохраняем как доказательство),
  - условия выполнения (если зависят от стенда/режима).
- Не “додумывать” факты (версии ОС, числа, пороги, SLA, конкретные инструменты), если их нет в `docs/`.
  - Если данных нет: писать **«Не задано в docs (перечислить проверенные документы/разделы)»**.

---

## Структура готового ПМИ (содержимое выходного файла)

### 1. Титульная часть
- Программа и методика испытаний
- Наименование: `<PROJECT_NAME>`
- Вид испытаний (если определено в `docs/`)
- Версия/дата
- Нормативные ссылки (если заданы в `docs/`)
- Исполнители/ответственные (если заданы в `docs/`)

### 2. Общие положения
- Назначение испытаний
- Объект испытаний и границы (in scope / out of scope) — только по `docs/`
- Основания: перечень документов из `docs/`, на которых основана ПМИ

### 3. Приёмочные критерии и проверяемые требования
- Перечень критериев/требований с точными порогами/условиями
- Для каждого пункта: ссылка на `docs/` (документ + пункт/раздел)

### 4. Условия проведения испытаний
- Испытательный стенд (состав, компоненты, роли узлов) — по `docs/`
- ПО и средства (ОС, сервисы, БД, клиенты) — по `docs/`
- Конфигурации/версии — по `docs/`
- Сетевые условия/ограничения, синхронизация времени — если есть в `docs/`
- Контроль работоспособности (логи/health/метрики) — если есть в `docs/`
- Исключения (out of scope) — только по `docs/`

### 5. Подготовка к испытаниям
- Проверка комплектности поставки и документации
- Подготовка окружения — если описано в `docs/`
- Подготовка тест-данных — если требуется и описано в `docs/`
- Критерии готовности к началу испытаний (entry criteria) — если определены, иначе сформулировать как проверяемые условия на основе `docs/`

### 6. Программа испытаний (реестр проверок)
Оформить таблицей.

**Реестр проверок**
| ID проверки | Наименование | Источник (docs + пункт/раздел) | Что проверяем / параметр | Вид испытаний | Условия/стенд | Артефакты | Критерий pass/fail |
|---|---|---|---|---|---|---|---|
| T-001 | ... | «...», (docs/... раздел ...) | ... | ... | ... | ... | ... |

Правила реестра:
- `ID проверки` уникален и используется как ссылка внутри документа.
- “Источник” — конкретный документ из `docs/` и конкретный пункт/раздел.
- “Критерий pass/fail” — однозначный и проверяемый.
- “Артефакты” — перечислить доказательства прохождения/провала.

### 7. Методики испытаний (по ID проверки)
Для каждого `T-###` оформить отдельный подпункт:

#### T-001 — <наименование>
- **Цель:** ...
- **Основание:** «...», (docs/... пункт/раздел ...)
- **Средства:** ... (строго по `docs/`; если не задано — “не задано в docs”)
- **Шаги:**
  1) ...
  2) ...
- **Ожидаемый результат:** ... (pass/fail)
- **Артефакты:** ...
- **Оценка соответствия:** да / нет / частично

(Повторить для всех проверок из реестра.)

### 8. Порядок проведения испытаний
- Логическая последовательность этапов (этапы описать словами: “проверка готовности”, “функциональные проверки”, “проверки нагрузочных критериев”, “проверки устойчивости”, “проверки безопасности” и т.п.)
- Правило перехода между этапами (после фиксации результатов предыдущего этапа)
- Режимы испытаний (длительность, интенсивность, повторы) — только если задано в `docs/`, иначе “не задано в docs”

### 9. Протоколирование и отчётность
- Что фиксируется по каждой проверке (результат, измеренные значения, ссылки на артефакты)
- Форма протокола (минимум таблица):
  | ID проверки | Результат | Измерения/значения | Замечания | Ссылки на артефакты |
- Форма итогового отчёта: сводка, отклонения, дефекты, вывод

### 10. Критерии завершения испытаний
- Условия завершения (exit criteria): выполнены обязательные проверки, достигнуты приёмочные критерии, нет блокирующих отклонений
- Если критерии/правила заданы в `docs/` — сослаться; иначе сформулировать по разделу 3 (приёмочные критерии)

### 11. Работы после завершения испытаний
- Сбор и архивирование артефактов
- Подготовка и утверждение итогового протокола/отчёта
- Перечень замечаний и дальнейшие действия (если предусмотрено в `docs/`)

---

## Примеры (H7)

**Считать верным:**
- В реестре проверок есть ID, источник в `docs/`, артефакты и критерий pass/fail.
- Для каждого T-### описаны шаги, средства и ожидаемый результат.

**Считать неверным:**
- Реестр проверок без источников и критериев.
- Методики испытаний описаны общими словами без шагов.

---

## Критерии готовности

- [ ] Заполнены разделы 1–11
- [ ] Реестр проверок и методики T-### заполнены и согласованы с `docs/`
- [ ] Описаны условия стенда, порядок проведения и протоколирование

---

## Definition of Done для выходного файла
Файл `docs/requirements/тестирование/испытание системы.md` считается готовым, если:
- заполнены разделы 1–11;
- в разделе 3 все приёмочные критерии имеют ссылки на `docs/` и точные условия/пороги;
- реестр проверок (раздел 6) заполнен, и у каждой строки есть источник, pass/fail и артефакты;
- для каждой строки реестра есть методика в разделе 7;
- описаны условия стенда (раздел 4), порядок проведения (раздел 8) и правила протоколирования (раздел 9).
